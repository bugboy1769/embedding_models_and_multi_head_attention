## Text Embedding Models, Multi Head Attention Implementation and a small RAG implementation (Could be two repos)

  * Embedding Models: Continuous Bag of Words, N-Gram Embedding Model. Small training run and forward pass for both.
  * Multi Head Attention: Transformer Encoder and half a Decoder in pytorch, need to finish writing the decoder. Conceptual comments scattered across.
  * RAG: Simple RAG Engine that takes in a url, chunks data and performs cosine similarity search on chunks.

ToDo: Encoder-Decoder Implementation for Transformer. SBERT Embedding Implementation. RAG idk, maybe some tests with chunking and similarity scores.

